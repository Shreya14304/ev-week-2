{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1694c007",
   "metadata": {},
   "source": [
    "# EV Sales Prediction & Adoption Analysis — Google Colab\n",
    "\n",
    "This Colab-ready notebook contains an end-to-end pipeline to load an EV sales dataset, do basic cleaning/EDA, train regression models for sales prediction and a classifier for adoption analysis, and save trained models.\n",
    "\n",
    "**How to use in Google Colab**\n",
    "1. Open Colab: https://colab.research.google.com\n",
    "2. Click **File → Upload notebook** and upload this file, or open it from your Google Drive.\n",
    "3. Upload `ev_sales.csv` into Colab (left sidebar → Files → Upload) or mount Google Drive and place the file there.\n",
    "\n",
    "Run cells sequentially. The notebook installs required packages automatically.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaafc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (runs once in Colab runtime)\n",
    "!pip install -q pandas numpy scikit-learn matplotlib seaborn xgboost joblib\n",
    "print('Packages installed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc359cc8",
   "metadata": {},
   "source": [
    "## Upload dataset\n",
    "\n",
    "You can upload your `ev_sales.csv` directly into Colab's temporary filesystem (left Files pane → Upload) or mount your Google Drive and load the file from there.\n",
    "\n",
    "If you prefer Drive, run the next cell and follow the authentication steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331737b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Use files.upload (manual upload)\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "# After upload, make sure the filename (e.g. 'ev_sales.csv') appears in uploaded.keys()\n",
    "print('Uploaded files:', list(uploaded.keys()))\n",
    "\n",
    "# Option B: Mount Google Drive (persistent across sessions if you save in Drive)\n",
    "from google.colab import drive\n",
    "print('If you want to use Google Drive instead, uncomment drive.mount below and provide path to file in the code cells')\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d130cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import joblib\n",
    "\n",
    "print('Libraries imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c63049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the filename below if your file has a different name or path\n",
    "DATAFILE = 'ev_sales.csv'\n",
    "\n",
    "# Try to read file\n",
    "import os\n",
    "if not os.path.exists(DATAFILE):\n",
    "    print(f\"{DATAFILE} not found in current working directory. Use the Files pane to upload or mount Drive and update DATAFILE path.\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATAFILE)\n",
    "    print('Loaded', DATAFILE)\n",
    "    print('Shape:', df.shape)\n",
    "except Exception as e:\n",
    "    print('Error loading file:', e)\n",
    "    df = None\n",
    "\n",
    "# Quick peek\n",
    "if df is not None:\n",
    "    display(df.head())\n",
    "    print('\\nColumns:', df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f820ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick inspection and basic cleaning\n",
    "if df is None:\n",
    "    raise SystemExit('Upload the dataset first')\n",
    "\n",
    "print('\\n-- INFO --')\n",
    "print(df.info())\n",
    "print('\\n-- NULL counts --')\n",
    "print(df.isnull().sum().sort_values(ascending=False).head(20))\n",
    "\n",
    "# Attempt to create 'year' if possible\n",
    "for candidate in ['Year', 'year', 'sale_year', 'date', 'Date']:\n",
    "    if candidate in df.columns:\n",
    "        try:\n",
    "            df['year'] = pd.to_datetime(df[candidate]).dt.year\n",
    "        except Exception:\n",
    "            try:\n",
    "                df['year'] = df[candidate].astype(int)\n",
    "            except Exception:\n",
    "                pass\n",
    "        break\n",
    "\n",
    "# Find sales column\n",
    "sales_col = None\n",
    "for c in ['sales', 'units_sold', 'units', 'quantity']:\n",
    "    if c in df.columns:\n",
    "        sales_col = c\n",
    "        break\n",
    "\n",
    "if sales_col is None:\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if numeric_cols:\n",
    "        sales_col = numeric_cols[0]\n",
    "        print(f\"No explicit sales column found — using numeric column '{sales_col}' as target. Double-check this.\")\n",
    "    else:\n",
    "        raise ValueError('No numeric column found to use as sales target')\n",
    "\n",
    "print('\\nUsing sales column:', sales_col)\n",
    "\n",
    "# Make copies\n",
    "orig_df = df.copy()\n",
    "\n",
    "# Drop rows without sales target\n",
    "df = df.dropna(subset=[sales_col])\n",
    "\n",
    "# Create example categorical and numeric lists (modify as needed)\n",
    "cat_cols = []\n",
    "for c in ['country','region','make','manufacturer','model']:\n",
    "    if c in df.columns:\n",
    "        cat_cols.append(c)\n",
    "\n",
    "num_cols = []\n",
    "for c in ['battery_kWh','battery_capacity','range_km','range_miles','price','list_price','co2_emissions','year']:\n",
    "    if c in df.columns:\n",
    "        num_cols.append(c)\n",
    "\n",
    "# Fill missing numeric with median and categorical with 'Unknown'\n",
    "for c in num_cols:\n",
    "    df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "    if df[c].isnull().any():\n",
    "        df[c] = df[c].fillna(df[c].median())\n",
    "for c in cat_cols:\n",
    "    df[c] = df[c].astype(str).fillna('Unknown')\n",
    "\n",
    "print('\\nCategorical features:', cat_cols)\n",
    "print('Numerical features:', num_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080419cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create adoption label (binary)\n",
    "adoption_threshold = 0\n",
    "adopt_col = 'adopted'\n",
    "df[adopt_col] = (df[sales_col] > adoption_threshold).astype(int)\n",
    "\n",
    "# Basic EDA plots\n",
    "import matplotlib\n",
    "plt.style.use('default')\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title('Distribution of sales')\n",
    "try:\n",
    "    sns.histplot(df[sales_col], bins=50)\n",
    "except Exception:\n",
    "    plt.hist(df[sales_col].dropna(), bins=50)\n",
    "plt.show()\n",
    "\n",
    "if 'year' in df.columns:\n",
    "    yearly = df.groupby('year')[sales_col].sum().reset_index()\n",
    "    plt.figure(figsize=(10,4))\n",
    "    sns.lineplot(data=yearly, x='year', y=sales_col)\n",
    "    plt.title('Total sales by year')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b71de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Regression: Sales prediction ----\n",
    "feature_cols = num_cols + cat_cols\n",
    "if not feature_cols:\n",
    "    feature_cols = [c for c in df.columns if c not in [sales_col, adopt_col]]\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df[sales_col].astype(float)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "numeric_features = [c for c in feature_cols if c in num_cols]\n",
    "categorical_features = [c for c in feature_cols if c in cat_cols]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "cat_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', cat_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'RandomForest': RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1),\n",
    "    'XGBoost': XGBRegressor(n_estimators=200, random_state=42, verbosity=0)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "best_rmse = float('inf')\n",
    "best_pipeline = None\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = pipe.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    results[name] = {'rmse': rmse, 'mae': mae, 'r2': r2}\n",
    "    print(f\"{name} -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_pipeline = pipe\n",
    "\n",
    "print('\\nBest model by RMSE:', best_rmse)\n",
    "\n",
    "# Save the best regressor\n",
    "joblib.dump(best_pipeline, 'best_ev_regressor.joblib')\n",
    "print('Saved best_ev_regressor.joblib')\n",
    "\n",
    "# Show sample predictions\n",
    "print('\\nSample actual vs predicted:')\n",
    "print(pd.DataFrame({'actual': y_test.iloc[:8].values, 'pred': best_pipeline.predict(X_test.iloc[:8])}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dac76f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Classification: Adoption prediction ----\n",
    "Xc = df[feature_cols].copy()\n",
    "yc = df[adopt_col]\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(Xc, yc, test_size=0.2, random_state=42)\n",
    "\n",
    "clf_pipe = Pipeline(steps=[('preprocessor', preprocessor), ('clf', RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1))])\n",
    "clf_pipe.fit(Xc_train, yc_train)\n",
    "\n",
    "preds = clf_pipe.predict(Xc_test)\n",
    "print('\\nClassification report:\\n')\n",
    "print(classification_report(yc_test, preds))\n",
    "print('\\nConfusion matrix:\\n', confusion_matrix(yc_test, preds))\n",
    "\n",
    "# Save classifier\n",
    "joblib.dump(clf_pipe, 'ev_adoption_classifier.joblib')\n",
    "print('Saved ev_adoption_classifier.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c157bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (if available)\n",
    "try:\n",
    "    model = best_pipeline.named_steps['model']\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        # attempt to reconstruct feature names\n",
    "        num_feats = numeric_features\n",
    "        ohe = best_pipeline.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot']\n",
    "        cat_feat_names = ohe.get_feature_names_out(categorical_features).tolist()\n",
    "        feat_names = num_feats + cat_feat_names\n",
    "        importances = model.feature_importances_\n",
    "        fi = pd.Series(importances, index=feat_names).sort_values(ascending=False).head(30)\n",
    "        display(fi)\n",
    "        fi.plot(kind='barh', figsize=(8,6));\n",
    "        plt.gca().invert_yaxis();\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('Best regressor does not provide feature_importances_')\n",
    "except Exception as e:\n",
    "    print('Could not compute feature importances:', e)\n",
    "\n",
    "print('\\nNotebook complete. Models saved in this runtime: best_ev_regressor.joblib and ev_adoption_classifier.joblib')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
